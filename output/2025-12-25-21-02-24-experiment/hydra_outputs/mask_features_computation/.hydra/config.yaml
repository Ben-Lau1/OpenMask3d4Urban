data:
  masks:
    masks_path: /home/zhangshuai/workshop/open_vocabulary/LqhSpace/openmask3d_old/openmask3d/output/2025-12-25-21-02-24-experiment/scene_example_masks.pt
  camera:
    poses_path: /home/zhangshuai/workshop/open_vocabulary/openmask3d/scene_example/pose
    intrinsic_path: /home/zhangshuai/workshop/open_vocabulary/openmask3d/scene_example/intrinsic/intrinsic_color.txt
    intrinsic_resolution:
    - 968
    - 1296
  depths:
    depths_path: /home/zhangshuai/workshop/open_vocabulary/openmask3d/scene_example/depth
    depths_ext: .png
    depth_scale: 1000
  images:
    images_path: /home/zhangshuai/workshop/open_vocabulary/openmask3d/scene_example/color
    images_ext: .jpg
  point_cloud_path: /home/zhangshuai/workshop/open_vocabulary/openmask3d/scene_example/scene_example.ply
openmask3d:
  top_k: 5
  multi_level_expansion_ratio: 0.1
  num_of_levels: 3
  vis_threshold: 0.2
  frequency: 10
  num_random_rounds: 10
  num_selected_points: 5
external:
  sam_checkpoint: /home/zhangshuai/workshop/open_vocabulary/openmask3d/sam_vit_h_4b8939.pth
  sam_model_type: vit_h
  clip_model: ViT-L/14@336px
output:
  experiment_name: experiment
  output_directory: /home/zhangshuai/workshop/open_vocabulary/LqhSpace/openmask3d_old/openmask3d/output/2025-12-25-21-02-24-experiment
  save_crops: false
gpu:
  optimize_gpu_usage: false
